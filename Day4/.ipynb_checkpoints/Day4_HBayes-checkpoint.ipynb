{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28c2316d",
   "metadata": {},
   "source": [
    "# Problem 1: The Eight Schools\n",
    "\n",
    "Students at eight schools each participated in a test-prep program. After examination, the average score improvement $ \\Delta S$ for each school was recorded, along with the uncertainty on this measurement $ \\sigma( \\Delta S)$:\n",
    "\n",
    "   + $ \\Delta S$ = [28, 8, -3, 7, -1, 1, 18, 12]\n",
    "\n",
    "   + $ \\sigma( \\Delta S$) = [15, 10, 16, 11, 9, 11, 10, 18]\n",
    "\n",
    "\n",
    "a) Calculate the pooled mean improvement and uncertainty on the mean\n",
    "\n",
    "b) Fit the data using a hierarchical modeling. Assuming the score improvements $\\theta = \\Delta S$ were drawn from a population that can be modeled as a Gaussian with mean $\\mu$ and uncertainty $\\sigma$.\n",
    "\n",
    "* i. Draw your hyperparameters $\\alpha = \\{\\mu, \\sigma\\}$ from a Gaussian and Half-Cauchy distribution, respectively\n",
    "* ii. Test other choices of distributions for the hyper-priors and population. How sensitive are the results?\n",
    "\n",
    "Sample from the posterior using a sampling method of your choice. Test the sampler runs for convergence. Explore sampler behavior when using centered vs. off-centered parameterization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26904566-9d77-4d2e-8013-14147bbf3072",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "import emcee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "836b9afb-f3f4-4112-80d7-0c06e53e7ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooled mean S: 7.685616724956035\n",
      "uncertainty: 4.071919158402296\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "delS = [28,8,-3,7,-1,1,18,12]\n",
    "sigS = [15,10,16,11,9,11,10,18]\n",
    "schools = ['A','B','C','D','E','F','G','H']\n",
    "\n",
    "data = {'delS':delS,'sigS':sigS,'schools':schools}\n",
    "\n",
    "data['w'] = 1 / np.power(data['sigS'],2)\n",
    "# part a\n",
    "print('pooled mean S:',np.sum(data['w']*data['delS'])/np.sum(data['w']))\n",
    "print('uncertainty:',np.power(np.sum(data['w']),-0.5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b3912e-029f-4ead-9439-a3ec8cfaa60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# part b\n",
    "def model(mu_0,sigma_0):\n",
    "    model = stats.norm(loc=mu_0,scale=sigma_0)\n",
    "    return model\n",
    "\n",
    "def log_prior(theta):\n",
    "    mu = stats.norm.rvs(loc=0,scale=10)\n",
    "    sigma = stats.halfcauchy.rvs(loc=2)\n",
    "    \n",
    "    pdf = stats.norm.pdf(loc=mu,scale=sigma)\n",
    "    return pdf\n",
    "\n",
    "def log_likelihood(theta, x, y, yerr):\n",
    "    mu, sigma = theta\n",
    "    y = stats.norm.rvs(loc=mu,scale=sigma)\n",
    "    yerr = \n",
    "    return -0.5 * np.sum(((y - model) / yerr)**2)\n",
    "    \n",
    "def log_probability(theta, x, y, yerr):\n",
    "    lp = log_prior(theta)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    return lp + log_likelihood(theta, x, y, yerr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd8f576",
   "metadata": {},
   "source": [
    "# Problem 2: The Five Districts\n",
    "\n",
    "The test-prep program was expanded across five districts, for a total of 27 schools. For each school, the mean score improvement, uncertainty on the mean, and number of hours each student spent studying was recorded.\n",
    "\n",
    "### Exercises\n",
    "\n",
    "a) Load the Five Districts dataset (five_districts.csv) and plot the data\n",
    "b) Determine the expected score improvement per hour studied for each school using three different models:\n",
    "\n",
    "+ i. A fully pooled model\n",
    "+ ii. Independent estimates for each district\n",
    "+ iii. A hierarchical model that asserts a relationship between the schools and districts.\n",
    "\n",
    "For all three cases, sample from the posterior using a sampling method of your choice. Test the sampler runs for convergence. Explore sampler behavior when using centered vs. off-centered parameterization.\n",
    "\n",
    "For the third option, draw the relationship as a directed acyclic graph. Justify your choices of distributions for parameters and hyper-parameters, and test your results for sensitivity to modeling choices.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc8353a",
   "metadata": {},
   "source": [
    "# Problem 3: Dyson Spheres\n",
    "\n",
    "Congratulations! You've detected a strange class of objects that you suspect are [Dyson spheres](https://en.wikipedia.org/wiki/Dyson_sphere). Your data are sparse, but you nonetheless detect hints of variability in each object's brightness.\n",
    "\n",
    "a) Load the Dyson Sphere dataset (dyson_spheres.csv) and plot the time series data. What do you notice about the relative amplitude variations?\n",
    "\n",
    "b) For each object, compute a Lomb-Scargle periodogram. What do you notice about the frequency-power plot?\n",
    "\n",
    "c) Assume that each object's time series can be modeled as a single-component sinusoid. Construct a hierarchical model for the population, asserting some population-level relationship between the amplitudes, frequencies, and phases for each object's sinusoid. Which parameters might be expected to be correlated or independent of one another?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf55ef0d",
   "metadata": {},
   "source": [
    "# Problem 4: Astrophysics\n",
    "\n",
    "Select an astrophysical dataset of your choosing. Describe any hierarchical structure in the data using a directed acyclic graph. Build a simple hierarchical model for the data. You may wish to use only a few member objects of your dataset in order to more rapidly iterate while developing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f1ea5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
